{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data():\n",
    "    \"\"\"\n",
    "    Return a list of strings (where words have spaces correctly between them) for each sentiment\n",
    "    \"\"\"\n",
    "    t = pd.read_table('./Datasets/Rotten_Tomatoes/train.tsv')\n",
    "    negative = t[t['Sentiment'] == 0].append(t[t['Sentiment'] == 1])\n",
    "#     negative = t[t['Sentiment'] == 0]\n",
    "    negative.sort_values('PhraseId', inplace=True)\n",
    "    negative.drop_duplicates('SentenceId', keep='first', inplace=True)\n",
    "    \n",
    "    neutral = t[t['Sentiment'] == 2]\n",
    "#     neutral = t[t['Sentiment'] == 1].append(t[t['Sentiment'] == 2]).append(t[t['Sentiment'] == 3])\n",
    "    neutral.sort_values('PhraseId', inplace=True)\n",
    "    neutral.drop_duplicates('SentenceId', keep='first', inplace=True)\n",
    "    \n",
    "    positive = t[t['Sentiment'] == 3].append(t[t['Sentiment'] == 4])\n",
    "#     positive = t[t['Sentiment'] == 4]\n",
    "    positive.sort_values('PhraseId', inplace=True)\n",
    "    positive.drop_duplicates('SentenceId', keep='first', inplace=True)\n",
    "    \n",
    "    return negative['Phrase'].tolist(), neutral['Phrase'].tolist(), positive['Phrase'].tolist()\n",
    "\n",
    "\n",
    "def prepare_data(negative_reviews_train, neutral_reviews_train, positive_reviews_train):\n",
    "    \"\"\"\n",
    "    Since 3 classes, ensure each class has baseline of 33.33% for guessing. We also do 3-fold cross-validation so each fold needs\n",
    "    to have the correct proportion of classes too to keep above baseline using stratified k fold cross validation.\n",
    "    \"\"\"\n",
    "    min_size = min([len(negative_reviews_train), len(neutral_reviews_train), len(positive_reviews_train)])\n",
    "\n",
    "    # So that baseline of random guessing is now 33.33%\n",
    "    negative_reviews_train = negative_reviews_train[:min_size]\n",
    "    neutral_reviews_train = neutral_reviews_train[:min_size]\n",
    "    positive_reviews_train = positive_reviews_train[:min_size]\n",
    "    \n",
    "    neg_label = [-1] * min_size\n",
    "    neutral_label = [0] * min_size\n",
    "    pos_label = [1] * min_size\n",
    "    \n",
    "    data = []\n",
    "    data.extend(negative_reviews_train)\n",
    "    data.extend(neutral_reviews_train)\n",
    "    data.extend(positive_reviews_train)\n",
    "    data = np.array(data)\n",
    "    \n",
    "    labels = []\n",
    "    labels.extend(neg_label)\n",
    "    labels.extend(neutral_label)\n",
    "    labels.extend(pos_label)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=3)\n",
    "    train_indices = []\n",
    "    test_indices = []\n",
    "    for train_index, test_index in skf.split(data, labels):\n",
    "        train_indices.append(train_index)\n",
    "        test_indices.append(test_index)\n",
    "        print(\"TRAIN:\", len(train_index), \"TEST:\", len(test_index))\n",
    "    \n",
    "    return data, labels, train_indices, test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6092\n",
      "8115\n",
      "6794\n",
      "TRAIN: 12183 TEST: 6093\n",
      "TRAIN: 12183 TEST: 6093\n",
      "TRAIN: 12186 TEST: 6090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akkash/.local/lib/python3.5/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/home/akkash/.local/lib/python3.5/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "negative_reviews, neutral_reviews, positive_reviews = get_train_data()\n",
    "print(len(negative_reviews))\n",
    "print(len(neutral_reviews))\n",
    "print(len(positive_reviews))\n",
    "\n",
    "data, labels, train_indices, test_indices = prepare_data(negative_reviews, neutral_reviews, positive_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenise_document(review, add_not_tag=False, unigram=False, bigram=False, pos=False, position=False):\n",
    "    \"\"\"\n",
    "    Given a review (string) we return a list of tokens\n",
    "    \"\"\"\n",
    "    \n",
    "#     stemmer = PorterStemmer()\n",
    "#     review_split = [stemmer.stem(word) for word in list(map(lambda x: x.lower(), review.split()))]\n",
    "\n",
    "    review_split = review.split()\n",
    "    tokens = []\n",
    "    \n",
    "    if add_not_tag:\n",
    "        negation_word = {'not': True, \"isn't\": True, \"doesn't\": True, \"wasn't\":True, \"couldn't\": True, \"wouldn't\": True, \n",
    "                         \"didn't\": True}\n",
    "        punctuation = {'?': True, '!': True, '.': True, ',': True, ':': True, ';':True}\n",
    "\n",
    "        convert_word = False\n",
    "        for word in review_split:\n",
    "            if word in punctuation:\n",
    "                convert_word = False\n",
    "                tokens.append(word)\n",
    "                continue\n",
    "\n",
    "            if convert_word:\n",
    "                tokens.append('NOT_'+word)\n",
    "                continue\n",
    "\n",
    "            if word in negation_word:\n",
    "                convert_word = True\n",
    "                tokens.append(word)\n",
    "                continue\n",
    "            tokens.append(word)\n",
    "                \n",
    "                \n",
    "    if unigram:\n",
    "        tokens.extend(review_split)\n",
    "        \n",
    "        \n",
    "    if pos:\n",
    "        tags = pos_tag(review_split) # tags is a list of tuples: [(token, pos tag)]\n",
    "        # Append the POS tag to each word in 'tokens' to form a string. E.g. 'Peter' and 'NN' becomes 'Peter_NN'\n",
    "        # tokens have NOT tag added to them\n",
    "        tokens = [token+'_'+tag[1] for token, tag in zip(tokens, tags)]\n",
    "\n",
    "        \n",
    "    if bigram:\n",
    "        # Since one of the above two conditions will be fulfilled, 'tokens' will always have entries\n",
    "        for index in range(len(tokens) - 1):\n",
    "            word_1 = tokens[index]\n",
    "            word_2 = tokens[index + 1]\n",
    "            tokens[index] = word_1 + ' ' + word_2\n",
    "        if len(tokens) > 0:\n",
    "            tokens.pop()  # Take the last unigram word at end of tokens list\n",
    "\n",
    "        \n",
    "    if position:\n",
    "        # 'tokens' will already have been filled by this point by either 'unigram' or 'add_not_tag'\n",
    "        first_quarter_end = np.ceil(len(tokens) * 0.25)\n",
    "        middle_end = np.ceil(len(tokens) * 0.75)\n",
    "        # last_quarter = len(tokens)\n",
    "        \n",
    "        for index in range(len(tokens)):\n",
    "            if index < first_quarter_end:\n",
    "                to_append = 1\n",
    "            elif index < middle_end:\n",
    "                to_append = 2\n",
    "            else:\n",
    "                to_append = 3\n",
    "            tokens[index] = tokens[index]+'_'+str(to_append)\n",
    "        \n",
    "        \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabulary(add_not_tag=False, unigram=False, bigram=False, pos=False, adjectives=False, position=False, length=16162):\n",
    "    data = negative_reviews + neutral_reviews + positive_reviews  # We have a list of textual reviews (strings)\n",
    "    \n",
    "    freq = {}  # Since we are using dict, vocabulary will be unique\n",
    "    for review in data:\n",
    "        review_tokens = tokenise_document(review, unigram=unigram, add_not_tag=add_not_tag, bigram=bigram)\n",
    "\n",
    "        for token in review_tokens:\n",
    "            if token in freq:\n",
    "                freq[token] += 1\n",
    "            else:\n",
    "                freq[token] = 1\n",
    "                \n",
    "    if length is None:\n",
    "        cutoff = 7 if bigram else 4\n",
    "        vocabulary = set([token for token, count in freq.items() if count >= cutoff])\n",
    "    else:\n",
    "        sorted_freq = sorted([(count, token) for token, count in freq.items()], reverse=True)\n",
    "        vocabulary = set([token for _, token in sorted_freq[:length]])  # We use set to exploit O(1) lookup time\n",
    "    \n",
    "    \n",
    "    if pos or position:\n",
    "#         print(\"Entering POS/Position\")\n",
    "        vocabulary_pos = []\n",
    "        for i, review in enumerate(data):\n",
    "            \n",
    "#             if i % 100 == 0:\n",
    "#                 print(i)\n",
    "            \n",
    "            unigram_tokens = np.array(tokenise_document(review, unigram=unigram, add_not_tag=add_not_tag))\n",
    "            pos_tokens = np.array(tokenise_document(review, unigram=unigram, add_not_tag=add_not_tag, pos=pos, position=position))\n",
    "            mask = list(map(lambda token: token in vocabulary, unigram_tokens))\n",
    "            vocabulary_pos.extend(list(pos_tokens[mask]))\n",
    "        \n",
    "        freq = {}\n",
    "        for token in vocabulary_pos:\n",
    "            if token in freq:\n",
    "                freq[token] += 1\n",
    "            else:\n",
    "                freq[token] = 1\n",
    "\n",
    "        if length is None:\n",
    "            vocabulary = set([token for token, count in freq.items() if count >= 4])\n",
    "        else:\n",
    "            sorted_freq = sorted([(count, token) for token, count in freq.items()], reverse=True)\n",
    "            vocabulary = set([token for _, token in sorted_freq[:length]])\n",
    "            \n",
    "        \n",
    "    if adjectives:\n",
    "        # Filter the 'sored_freq' list to only contains words with tags that end in JJ/JJR/JJS\n",
    "        freq = {}\n",
    "        for review in data:\n",
    "            review_tokens = tokenise_document(review, unigram=unigram, add_not_tag=add_not_tag, pos=True)\n",
    "\n",
    "            for pos_token in review_tokens:\n",
    "                \n",
    "                if pos_token.endswith('JJ'):\n",
    "                    token = pos_token[:-3]\n",
    "                elif pos_token.endswith('JJR'):\n",
    "                    token = pos_token[:-4]\n",
    "                elif pos_token.endswith('JJS'):\n",
    "                    token = pos_token[:-4]\n",
    "                \n",
    "                if token in freq:\n",
    "                    freq[token] += 1\n",
    "                else:\n",
    "                    freq[token] = 1\n",
    "\n",
    "        sorted_freq = sorted([(count, token) for token, count in freq.items()], reverse=True)\n",
    "        vocabulary = set([token for _, token in sorted_freq[:length]])\n",
    "    \n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    \n",
    "    def __init__(self, vocabulary, tokenisation):\n",
    "        self.vocabulary = vocabulary\n",
    "        self.tokenisation = tokenisation\n",
    "\n",
    "        \n",
    "    def get_document_vector(self, document_tokens):\n",
    "        freq = {v:0 for v in self.vocabulary}\n",
    "        for word in document_tokens:\n",
    "            if word in self.vocabulary:\n",
    "                freq[word] = 1\n",
    "        return freq\n",
    "    \n",
    "    \n",
    "    def get_class_probabilities(self, class_data):\n",
    "        \"\"\"\n",
    "        class_data: A list containing all the tokens in a training data document. P(f_i|c) from training documents\n",
    "        \"\"\"\n",
    "        # We start with the add-one smoothing\n",
    "        log_prob_dict = {v:1 for v in self.vocabulary}  # We encode the add one smoothing count at start\n",
    "        \n",
    "        total_class_tokens = 0  # Tokens contained in vocabulary\n",
    "        for word in class_data:\n",
    "            if word in self.vocabulary:\n",
    "                log_prob_dict[word] += 1\n",
    "                total_class_tokens += 1\n",
    "                \n",
    "        # We divide by the denominator and log the values\n",
    "        for key in log_prob_dict.keys():\n",
    "            log_prob_dict[key] = np.log(log_prob_dict[key] / (total_class_tokens + len(self.vocabulary)))\n",
    "\n",
    "        return log_prob_dict\n",
    "\n",
    "    \n",
    "    def split_data(self, indices):\n",
    "        \"\"\"\n",
    "        Given the indices (list of numbers). Split 'data' into negative, neutral and positive sentiments using 'labels'\n",
    "        \"\"\"\n",
    "        subset_data = data[indices]\n",
    "        subset_labels = labels[indices]\n",
    "        \n",
    "        negative_sentiments = np.where(subset_labels == -1)[0]\n",
    "        \n",
    "        neutral_sentiments = np.where(subset_labels == 0)[0]\n",
    "        \n",
    "        positive_sentiments = np.where(subset_labels == 1)[0]\n",
    "        \n",
    "        return subset_data[negative_sentiments], subset_data[neutral_sentiments], subset_data[positive_sentiments]\n",
    "    \n",
    "    \n",
    "    def train_probabilities(self, train_index1, train_index2):\n",
    "        neg_reviews_1, neutral_reviews_1, pos_reviews_1  = self.split_data(train_indices[train_index1])\n",
    "        print(\"Training_fold_1\")\n",
    "        print(len(neg_reviews_1), len(neutral_reviews_1), len(pos_reviews_1))\n",
    "        \n",
    "        print(\"Training_fold_2\")\n",
    "        neg_reviews_2, neutral_reviews_2, pos_reviews_2 = self.split_data(train_indices[train_index2])\n",
    "        print(len(neg_reviews_2), len(neutral_reviews_2), len(pos_reviews_2))\n",
    "        \n",
    "        \n",
    "        neg_train_tokens = []\n",
    "        for neg_review in np.concatenate((neg_reviews_1, neg_reviews_2), axis=0):\n",
    "            neg_review = self.tokenisation(neg_review)\n",
    "            neg_train_tokens.extend(neg_review)\n",
    "        negative_log_probs = self.get_class_probabilities(neg_train_tokens)\n",
    "        \n",
    "        print(\"Trained neg\")\n",
    "        \n",
    "        pos_train_tokens = []\n",
    "        for pos_review in np.concatenate((pos_reviews_1, pos_reviews_2), axis=0):\n",
    "            pos_review = self.tokenisation(pos_review)\n",
    "            pos_train_tokens.extend(pos_review)\n",
    "        positive_log_probs = self.get_class_probabilities(pos_train_tokens)\n",
    "        \n",
    "        print(\"Trained pos\")\n",
    "        \n",
    "        neutral_train_tokens = []\n",
    "        for neutral_review in np.concatenate((neutral_reviews_1, neutral_reviews_2), axis=0):\n",
    "            neutral_review = self.tokenisation(neutral_review)\n",
    "            neutral_train_tokens.extend(neutral_review)\n",
    "        neutral_log_probs = self.get_class_probabilities(neutral_train_tokens)\n",
    "        \n",
    "        print(\"Trained neutral\")\n",
    "    \n",
    "        return negative_log_probs, neutral_log_probs, positive_log_probs\n",
    "    \n",
    "    \n",
    "    def test_documents(self, test_index, negative_log_probs, neutral_log_probs, positive_log_probs):\n",
    "        negative_reviews, neutral_reviews, positive_reviews = self.split_data(test_indices[test_index])\n",
    "        \n",
    "        correct = 0\n",
    "        for pos_review in positive_reviews:\n",
    "            pos_review = self.tokenisation(pos_review)\n",
    "            document_vector = self.get_document_vector(pos_review)\n",
    "            \n",
    "            neg_sum = 0   # For negative class\n",
    "            neu_sum = 0   # For neutral class\n",
    "            pos_sum = 0   # For positive class\n",
    "            \n",
    "            for word, freq in document_vector.items():\n",
    "                # When we use counts in feature vector use below two    \n",
    "                if freq == 0:\n",
    "                    continue\n",
    "                    \n",
    "                neg_sum += negative_log_probs[word]\n",
    "                pos_sum += positive_log_probs[word]\n",
    "                neu_sum += neutral_log_probs[word]\n",
    "\n",
    "            if pos_sum > neg_sum and pos_sum > neu_sum:\n",
    "                correct += 1\n",
    "                \n",
    "        print(\"Tested pos\")\n",
    "        \n",
    "        for neu_review in neutral_reviews:\n",
    "            neu_review = self.tokenisation(neu_review)\n",
    "            document_vector = self.get_document_vector(neu_review)\n",
    "            \n",
    "            neg_sum = 0   # For negative class\n",
    "            neu_sum = 0   # For neutral class\n",
    "            pos_sum = 0   # For positive class\n",
    "            \n",
    "            for word, freq in document_vector.items():\n",
    "                # When we use counts in feature vector use below two\n",
    "                if freq == 0:\n",
    "                    continue\n",
    "                    \n",
    "                neg_sum += document_vector[word] * negative_log_probs[word]\n",
    "                pos_sum += document_vector[word] * positive_log_probs[word]\n",
    "                neu_sum += document_vector[word] * neutral_log_probs[word]\n",
    "\n",
    "            if neu_sum > neg_sum and neu_sum > pos_sum:\n",
    "                correct += 1\n",
    "                \n",
    "        print(\"Tested neutral\")\n",
    "        \n",
    "        for neg_review in negative_reviews:\n",
    "            neg_review = self.tokenisation(neg_review)\n",
    "            document_vector = self.get_document_vector(neg_review)\n",
    "            \n",
    "            neg_sum = 0   # For negative class\n",
    "            neu_sum = 0\n",
    "            pos_sum = 0   # For positive class\n",
    "            \n",
    "            for word, freq in document_vector.items():\n",
    "                if freq == 0:\n",
    "                    continue\n",
    "                    \n",
    "                neg_sum += document_vector[word] * negative_log_probs[word]\n",
    "                pos_sum += document_vector[word] * positive_log_probs[word]\n",
    "                neu_sum += document_vector[word] * neutral_log_probs[word]\n",
    "                \n",
    "            if neg_sum > pos_sum and neg_sum > neu_sum:\n",
    "                correct += 1\n",
    "                \n",
    "        print(\"Tested neg\")\n",
    "\n",
    "        return correct / (len(negative_reviews) + len(positive_reviews) + len(neutral_reviews))\n",
    "    \n",
    "    \n",
    "    def get_statistics(self):\n",
    "        train_index1, train_index2, test_index = 1, 2, 0\n",
    "        neg_log_prob, neu_log_prob, pos_log_prob = self.train_probabilities(train_index1, train_index2)\n",
    "        print(\"Trained\")\n",
    "        accuracy1 = self.test_documents(test_index, neg_log_prob, neu_log_prob, pos_log_prob)\n",
    "        print(\"Tested\")\n",
    "#         return accuracy1\n",
    "        \n",
    "        train_index1, train_index2, test_index = 0, 2, 1\n",
    "        neg_log_prob, neu_log_prob, pos_log_prob = self.train_probabilities(train_index1, train_index2)\n",
    "        accuracy2 = self.test_documents(test_index, neg_log_prob, neu_log_prob, pos_log_prob)\n",
    "        \n",
    "        train_index1, train_index2, test_index = 0, 1, 2\n",
    "        neg_log_prob, neu_log_prob, pos_log_prob = self.train_probabilities(train_index1, train_index2)\n",
    "        accuracy3 = self.test_documents(test_index, neg_log_prob, neu_log_prob, pos_log_prob)\n",
    "        \n",
    "        return (accuracy1 + accuracy2 + accuracy3) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29461\n"
     ]
    }
   ],
   "source": [
    "vocabulary_unigram = get_vocabulary(add_not_tag=True)\n",
    "# vocabulary_bigram = get_vocabulary(unigram=True, bigram=True)\n",
    "# vocabulary = vocabulary_unigram | vocabulary_bigram\n",
    "def tokenisation(x):\n",
    "    unigrams = tokenise_document(x, add_not_tag=True)\n",
    "    bigrams = tokenise_document(x, unigram=True, bigram=True)\n",
    "    unigrams.extend(bigrams)\n",
    "    return unigrams\n",
    "\n",
    "# vocabulary = get_vocabulary(add_not_tag=True)\n",
    "# tokenisation = lambda x: tokenise_document(x, add_not_tag=True)\n",
    "\n",
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16162"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary_unigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13299"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary_unigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Again',\n",
       " 'substance',\n",
       " 'at his',\n",
       " 'A small',\n",
       " 'Sabara',\n",
       " 'Mario',\n",
       " 'has too',\n",
       " 'strange and',\n",
       " 'Brett',\n",
       " 'Iran',\n",
       " 'technical flaws',\n",
       " 'trashy',\n",
       " 'labours',\n",
       " 'the music',\n",
       " 'cursory',\n",
       " 'NOT_one',\n",
       " 'is an',\n",
       " 'has made',\n",
       " 'nonsense',\n",
       " 'alongside',\n",
       " 'succumbs to',\n",
       " ', absurd',\n",
       " 'us a',\n",
       " 'Oscar-sweeping',\n",
       " 'with an',\n",
       " 'produce adequate',\n",
       " 'willingness',\n",
       " 'fairy tale',\n",
       " '-LRB- Jaglom',\n",
       " 'warm',\n",
       " 'and Amazing',\n",
       " 'weeks',\n",
       " 'smack',\n",
       " 'patriarchal',\n",
       " 'fits the',\n",
       " 'in her',\n",
       " 'movie has',\n",
       " 'helped',\n",
       " 'seemingly',\n",
       " 'slasher-movie',\n",
       " 'inauthentic',\n",
       " 'A delightful',\n",
       " 'machines',\n",
       " 'those places',\n",
       " 'old are',\n",
       " 'women ,',\n",
       " 'to follow',\n",
       " 'laugh-out-loud bits',\n",
       " 'it portrays',\n",
       " 'alone',\n",
       " 'static',\n",
       " 'NOT_thriller',\n",
       " 'been done',\n",
       " ', political',\n",
       " 'Glory',\n",
       " 'sadness',\n",
       " 'NOT_performance',\n",
       " 'about how',\n",
       " 'cattle',\n",
       " 'loosely',\n",
       " 'chick',\n",
       " 'NOT_vulgar',\n",
       " 'animation is',\n",
       " ', featuring',\n",
       " 'tradition of',\n",
       " 'risks',\n",
       " 'dark humor',\n",
       " 'Butterworth',\n",
       " 'that do',\n",
       " 'It should',\n",
       " 'clothes and',\n",
       " 'mind --',\n",
       " 'no doubting',\n",
       " 'Taiwanese',\n",
       " 'year ,',\n",
       " 'valid',\n",
       " 'ploddingly',\n",
       " 'proficient ,',\n",
       " 'felt like',\n",
       " 'flow .',\n",
       " 'strange guy',\n",
       " 'know it',\n",
       " 'howlingly',\n",
       " 'to great',\n",
       " 'one forum',\n",
       " 'film only',\n",
       " 'A journey',\n",
       " 'objective',\n",
       " 'vivid ,',\n",
       " 'new to',\n",
       " 'Padre Amaro',\n",
       " 'Kaufman',\n",
       " 'NOT_straightforward',\n",
       " 'Ming-liang',\n",
       " 'blown',\n",
       " 'shocking thing',\n",
       " 'me for',\n",
       " ', nor',\n",
       " 'opportunities',\n",
       " 'evening',\n",
       " 'the life',\n",
       " 'poised',\n",
       " 'shapely',\n",
       " 'curtsy',\n",
       " 'me a',\n",
       " 'on hand',\n",
       " 'affectation-free',\n",
       " 'Fortune',\n",
       " 'treads',\n",
       " 'identity',\n",
       " 'great material',\n",
       " 'desire',\n",
       " 'characteristic',\n",
       " 'unanswered',\n",
       " ', made',\n",
       " 'awakening',\n",
       " 'the band',\n",
       " 'glory days',\n",
       " 'oh-those-wacky-Brits genre',\n",
       " 'Feathers',\n",
       " 'community .',\n",
       " 'unsurprising',\n",
       " 'experimental',\n",
       " 'ridiculous',\n",
       " 'American Beauty',\n",
       " 'linking the',\n",
       " 'Jennifer Lopez',\n",
       " 'footnote to',\n",
       " 'the profoundly',\n",
       " 'bewildering',\n",
       " 'Alabama',\n",
       " 'Theological',\n",
       " 'zings',\n",
       " 'NOT_showcases',\n",
       " 'been given',\n",
       " 'direction and',\n",
       " 'Jackson and',\n",
       " 'Them',\n",
       " 'injustices',\n",
       " 'unprecedented',\n",
       " 'awake',\n",
       " 'whiney',\n",
       " 'car',\n",
       " 'passed',\n",
       " 'it but',\n",
       " \"Schindler 's\",\n",
       " 'Sven',\n",
       " 'unsavory',\n",
       " 'special-interest',\n",
       " 'romp',\n",
       " 'shadow',\n",
       " 'inspires',\n",
       " 'lingered',\n",
       " 'in that',\n",
       " 'in Analyze',\n",
       " 'taken seriously',\n",
       " 'major studio',\n",
       " 'is a',\n",
       " 'only to',\n",
       " 'sweeping',\n",
       " 'Douglas',\n",
       " 'very least',\n",
       " 'natural',\n",
       " 'recklessness',\n",
       " 'diplomat',\n",
       " 'pretty funny',\n",
       " 'there .',\n",
       " 'of honest',\n",
       " 'cares ?',\n",
       " 'angle',\n",
       " 'Disappointingly',\n",
       " \"get '\",\n",
       " 'the many',\n",
       " 'cross between',\n",
       " 'got the',\n",
       " 'Silly',\n",
       " 'NOT_picture',\n",
       " 'tired retread',\n",
       " 'hero',\n",
       " 'top and',\n",
       " 'the `',\n",
       " 'journalism',\n",
       " 'approaches',\n",
       " 'these characters',\n",
       " 'happened ?',\n",
       " 'resolved',\n",
       " 'overall sense',\n",
       " \"'s always\",\n",
       " 'Jones',\n",
       " 'high-octane',\n",
       " 'gestures',\n",
       " 'three minutes',\n",
       " 'a haunting',\n",
       " 'the Dolls',\n",
       " 'surrounded',\n",
       " 'sides',\n",
       " 'NOT_charms',\n",
       " 'response',\n",
       " 'sure-fire',\n",
       " 'out-of-field',\n",
       " 'communication',\n",
       " 'big-budget\\\\/all-star',\n",
       " 'Defies',\n",
       " 'to what',\n",
       " 'is terrific',\n",
       " 'or maybe',\n",
       " 'humanizing',\n",
       " 'to avoid',\n",
       " 'either the',\n",
       " 'unwary',\n",
       " 'gags ,',\n",
       " 'embrace',\n",
       " 'leave us',\n",
       " 'explosions and',\n",
       " 'shape-shifting',\n",
       " 'who he',\n",
       " 'hates',\n",
       " 'unendurable viewing',\n",
       " 'journey is',\n",
       " 'Idemoto',\n",
       " 'post-September',\n",
       " 'most positive',\n",
       " 'three-hour',\n",
       " 'small-scale',\n",
       " 'Bow',\n",
       " 'conscious',\n",
       " 'ragbag',\n",
       " 'process itself',\n",
       " 'you will',\n",
       " 'to your',\n",
       " 'of quick',\n",
       " 'a routine',\n",
       " 'unsettled',\n",
       " 'poses',\n",
       " 'us by',\n",
       " 'Hanukkah',\n",
       " 'Slackers',\n",
       " 'struggled',\n",
       " 'have shaped',\n",
       " 'pleasure .',\n",
       " 'its animatronic',\n",
       " 'result',\n",
       " 'spectacular',\n",
       " 'of ultra-violent',\n",
       " 'anyway',\n",
       " 'violinist',\n",
       " 'so nice',\n",
       " 'understand ,',\n",
       " 'Chung',\n",
       " 'undertaken',\n",
       " 'react',\n",
       " 'reflects',\n",
       " 'making it',\n",
       " 'blacklight',\n",
       " 'intoxicating',\n",
       " 'of Khan',\n",
       " 'care .',\n",
       " 'based on',\n",
       " 'labelled',\n",
       " 'repetitively',\n",
       " 'human nature',\n",
       " 'hustler',\n",
       " 'journalists',\n",
       " 'to ever',\n",
       " 'major movie',\n",
       " 'recent Hollywood',\n",
       " '19th-Century',\n",
       " 'some movie',\n",
       " 'Norrington-directed',\n",
       " 'of Russian',\n",
       " 'Nick',\n",
       " 'tens',\n",
       " 'splatterfests',\n",
       " 'an odd',\n",
       " 'traveled',\n",
       " 'the women',\n",
       " 'man',\n",
       " 'putting together',\n",
       " 'drizzle',\n",
       " 'impish',\n",
       " 'schizo',\n",
       " 'accompanies',\n",
       " 'figure out',\n",
       " 'Israeli\\\\/Palestinian',\n",
       " 'memorable .',\n",
       " 'Machine is',\n",
       " 'knows how',\n",
       " 'dispossessed',\n",
       " 'odd situations',\n",
       " 'to hide',\n",
       " 'celebration',\n",
       " 'film does',\n",
       " 'Warner Bros.',\n",
       " 'rapturous',\n",
       " \"'s biggest\",\n",
       " 'quarter',\n",
       " 'presented',\n",
       " 'funniest',\n",
       " 'I am',\n",
       " 'melancholic',\n",
       " 'compulsively',\n",
       " 'enhances',\n",
       " 'swan',\n",
       " 'NOT_player',\n",
       " 'fresh as',\n",
       " 'peculiarly',\n",
       " 'its comedy',\n",
       " 'paranoid impulse',\n",
       " 'baffle',\n",
       " 'travails',\n",
       " 'the bullets',\n",
       " 'outward elements',\n",
       " 'waits',\n",
       " 'miscellaneous',\n",
       " 'learned a',\n",
       " 'all those',\n",
       " 'revelation',\n",
       " 'hype',\n",
       " 'girls-behaving-badly',\n",
       " 'the pantheon',\n",
       " '- it',\n",
       " \"'s more\",\n",
       " 'smiles',\n",
       " 'recite some',\n",
       " 'sink the',\n",
       " 'of animator',\n",
       " 'practically',\n",
       " 'offensive and',\n",
       " 'set of',\n",
       " 'outage',\n",
       " 'money back',\n",
       " 'sensitivities',\n",
       " 'hide-and-seek',\n",
       " 'a book',\n",
       " 'and Two',\n",
       " 'labors',\n",
       " 'moved',\n",
       " 'shabby',\n",
       " 'Christelle',\n",
       " 'selves',\n",
       " 'powerful ,',\n",
       " 'makers would',\n",
       " 'irrevocable choices',\n",
       " 'freewheeling trash-cinema',\n",
       " 'immigrant',\n",
       " 'promenade',\n",
       " 'real ,',\n",
       " 'NOT_give',\n",
       " 'stupid',\n",
       " 'least funny',\n",
       " 'talent is',\n",
       " 'comes out',\n",
       " 'hint of',\n",
       " '1.2',\n",
       " 'assassin',\n",
       " 'a delightful',\n",
       " 'short of',\n",
       " 'leave you',\n",
       " 'ennui',\n",
       " 'fax',\n",
       " 'adventures',\n",
       " 'barf bag',\n",
       " 'director Michael',\n",
       " 'alterations',\n",
       " 'that allows',\n",
       " 'setpieces',\n",
       " 'porcelain',\n",
       " 'coast',\n",
       " 'type',\n",
       " 'threadbare',\n",
       " 'favour',\n",
       " 'funk',\n",
       " '` they',\n",
       " 'Ellen',\n",
       " 'drowsy',\n",
       " 'Tron',\n",
       " 'Public',\n",
       " 'astonishing',\n",
       " 'L.A.',\n",
       " 'NOT_overcome',\n",
       " 'four Englishmen',\n",
       " 'simpering',\n",
       " 'weepy',\n",
       " 'an excellent',\n",
       " 'glimmer of',\n",
       " 'In addition',\n",
       " 'a perfectly',\n",
       " 'family .',\n",
       " 'worth rooting',\n",
       " 'NOT_sentence',\n",
       " 'latest eccentric',\n",
       " 'conscience',\n",
       " 'it did',\n",
       " 'freight',\n",
       " 'occasionally flawed',\n",
       " 'passable family',\n",
       " 'relationships',\n",
       " 'Broomsticks',\n",
       " 'where I',\n",
       " 'rich ,',\n",
       " 'breed',\n",
       " 'Exhibits',\n",
       " 'spry',\n",
       " 'overworked',\n",
       " 'misty-eyed',\n",
       " 'to offend',\n",
       " 'best of',\n",
       " 'bearing',\n",
       " 'promise ,',\n",
       " 'disrobed',\n",
       " 'passive',\n",
       " 'performances ...',\n",
       " 'cliques',\n",
       " 'first ,',\n",
       " \"' on\",\n",
       " 'crafting',\n",
       " 'surefire',\n",
       " 'little lemon',\n",
       " 'and also',\n",
       " 'more ,',\n",
       " 'to its',\n",
       " 'best work',\n",
       " 'what I',\n",
       " 'just did',\n",
       " 'ignored',\n",
       " 'Science',\n",
       " 'smarter-than-thou',\n",
       " ', rather',\n",
       " 'of decent',\n",
       " 'the sequel',\n",
       " 'quirky and',\n",
       " 'thought would',\n",
       " 'of Miramax',\n",
       " 'George Lucas',\n",
       " \"'s performance\",\n",
       " 'viewers',\n",
       " 'runs on',\n",
       " 'sleaze',\n",
       " 'NOT_so',\n",
       " 'Does',\n",
       " 'disdain',\n",
       " 'lensing',\n",
       " 'posits',\n",
       " 'through --',\n",
       " \"That 's\",\n",
       " 'sulking',\n",
       " 'uncertain film',\n",
       " 'rancorous',\n",
       " \"'ve already\",\n",
       " 'Sia',\n",
       " 'a passing',\n",
       " 'tastelessness and',\n",
       " 'Copy',\n",
       " 'perspective and',\n",
       " 'of money',\n",
       " 'its problems',\n",
       " 'will take',\n",
       " 'sensitive',\n",
       " 'essentially',\n",
       " 'That is',\n",
       " 'films in',\n",
       " 'Yoda',\n",
       " 'allegiance',\n",
       " 'abbreviated',\n",
       " 'a tale',\n",
       " 'is affecting',\n",
       " 'Resident',\n",
       " 'ricture',\n",
       " 'this rather',\n",
       " 'the protagonist',\n",
       " 'enjoying',\n",
       " 'the vehicle',\n",
       " 'some real',\n",
       " 'needy as',\n",
       " 'blab',\n",
       " 'successes such',\n",
       " 'Your',\n",
       " 'Fifty',\n",
       " 'not vintage',\n",
       " 'you really',\n",
       " 'a Hollywood',\n",
       " 'NOT_pure',\n",
       " 'Bond movie',\n",
       " 'boardwalk',\n",
       " 'Graphic',\n",
       " 'Woody Allen',\n",
       " 'pictures of',\n",
       " 'Mexican',\n",
       " 'and sprightly',\n",
       " 'It wo',\n",
       " 'Pow',\n",
       " 'worst possibilities',\n",
       " 'straight',\n",
       " 'like American',\n",
       " 'amusement',\n",
       " 'America',\n",
       " 'annoyances',\n",
       " 'penned',\n",
       " 'Although the',\n",
       " 'them to',\n",
       " 'the incomprehensible',\n",
       " 'years later',\n",
       " 'and sad',\n",
       " 'nonsensical and',\n",
       " 'updated',\n",
       " 'something fresh',\n",
       " 'Manages',\n",
       " 'strings',\n",
       " 'her mother',\n",
       " 'of entertainment',\n",
       " 'wraps',\n",
       " 'your',\n",
       " 'our infantilized',\n",
       " 'Festival',\n",
       " 'hack',\n",
       " 'discipline',\n",
       " 'your date',\n",
       " 'tough to',\n",
       " 'screwball',\n",
       " 'convey',\n",
       " 'is mostly',\n",
       " 'the trappings',\n",
       " 'means to',\n",
       " 'is not',\n",
       " 'Monty ,',\n",
       " 'sub',\n",
       " 'Lolita',\n",
       " 'anti-adult',\n",
       " 'NOT_appealing',\n",
       " 'contagious',\n",
       " 'omnibus',\n",
       " 'script by',\n",
       " 'Plutonium',\n",
       " 'summer diversion',\n",
       " 'rejection',\n",
       " 'warm-blooded',\n",
       " 'is ironically',\n",
       " 'explanations',\n",
       " 'write',\n",
       " 'makes your',\n",
       " 'trades',\n",
       " 'determined',\n",
       " 'Walter Hill',\n",
       " 'guilty pleasure',\n",
       " 'times when',\n",
       " 'it entertaining',\n",
       " 'have sprung',\n",
       " 'similarly themed',\n",
       " 'attentive',\n",
       " 'days ,',\n",
       " 'back-stabbing',\n",
       " 'frayed',\n",
       " 'popped',\n",
       " 'self-indulgence',\n",
       " 'sweat',\n",
       " 'execution and',\n",
       " 'Elizabeth',\n",
       " 'four-star',\n",
       " 'buddy movie',\n",
       " 'no ,',\n",
       " '; big',\n",
       " 'uplift',\n",
       " 'Driver-esque',\n",
       " 'tired ,',\n",
       " 'subscription',\n",
       " 'theaters since',\n",
       " 'praises female',\n",
       " 'guide',\n",
       " 'mean-spirited',\n",
       " 'ending .',\n",
       " 'set out',\n",
       " 'often-cute',\n",
       " 'but dull',\n",
       " 'futuristic',\n",
       " 'Muddled',\n",
       " 'equal',\n",
       " 'subtext',\n",
       " 'inescapable',\n",
       " 'Kaos',\n",
       " 'balloon',\n",
       " 'and devoid',\n",
       " 'flat',\n",
       " 'on that',\n",
       " 'nothing exactly',\n",
       " 'otherwise',\n",
       " 'incoherence',\n",
       " 'Fortunately',\n",
       " 'leaping',\n",
       " 'cheap thrills',\n",
       " 'seen that',\n",
       " 'mostly to',\n",
       " 'breaks',\n",
       " 'footage of',\n",
       " 'will undoubtedly',\n",
       " 'freedom',\n",
       " 'good and',\n",
       " 'Lightness',\n",
       " 'unremarkable',\n",
       " 'would you',\n",
       " 'verging',\n",
       " 'of Favor',\n",
       " 'kid',\n",
       " 'fans ,',\n",
       " 'Just when',\n",
       " 'of any',\n",
       " 'one of',\n",
       " 'holds itself',\n",
       " 'about their',\n",
       " 'short in',\n",
       " 'diversion .',\n",
       " 'area',\n",
       " 'residents',\n",
       " 'glimpses of',\n",
       " 'Onion',\n",
       " 'wary',\n",
       " 'NOT_thought',\n",
       " 'repeated',\n",
       " 'NOT_annals',\n",
       " 'minutes to',\n",
       " 'its stylistic',\n",
       " 'dyslexia',\n",
       " 'Oscar-winning',\n",
       " 'disappointment',\n",
       " 'overproduced',\n",
       " 'hour to',\n",
       " 'very Imaxy',\n",
       " 'NOT_striking',\n",
       " 'bracing',\n",
       " 'prince of',\n",
       " 'on three',\n",
       " 'to end',\n",
       " 'NOT_already',\n",
       " 'to being',\n",
       " 'dancers',\n",
       " 'before it',\n",
       " '11',\n",
       " 'Viveka',\n",
       " 'romp that',\n",
       " 'killer',\n",
       " 'competently',\n",
       " 'Woo',\n",
       " 'well-drawn',\n",
       " 'rare remakes',\n",
       " 'a Kiss',\n",
       " 'self-satisfied',\n",
       " 'a Russian',\n",
       " 'heft',\n",
       " 'resorting to',\n",
       " 'NOT_merit',\n",
       " 'the frustration',\n",
       " 'tumbleweeds',\n",
       " 'the two',\n",
       " \"'s hard\",\n",
       " 'we had',\n",
       " 'some levels',\n",
       " 'this otherwise',\n",
       " 'unexpectedly',\n",
       " 'plotless',\n",
       " 'lighted ,',\n",
       " 'differences',\n",
       " 'dramatized',\n",
       " 'sets',\n",
       " 'Gator-bashing',\n",
       " 'have killed',\n",
       " 'Bluer',\n",
       " ', bad',\n",
       " 'mends',\n",
       " 'seen ,',\n",
       " 'order to',\n",
       " 'passionate',\n",
       " 'parent vs.',\n",
       " 'character',\n",
       " ', however',\n",
       " 'of serial',\n",
       " 'understand',\n",
       " 'Evelyn',\n",
       " 'biting',\n",
       " 'fighters',\n",
       " 'of passion',\n",
       " 'a somewhat',\n",
       " 'pint-sized `',\n",
       " 'to his',\n",
       " 'Bart',\n",
       " \"'m\",\n",
       " 'entertained',\n",
       " 'squirming',\n",
       " 'sentiment and',\n",
       " 'featuring',\n",
       " 'rare that',\n",
       " 'that Hollywood',\n",
       " 'purge',\n",
       " 'magic of',\n",
       " 'uneven to',\n",
       " 'through its',\n",
       " 'punch .',\n",
       " 'evoked',\n",
       " 'Storytelling',\n",
       " 'twice',\n",
       " 'trumpet',\n",
       " 'Gedeck',\n",
       " 'outdoes',\n",
       " 'boiling',\n",
       " 'Sontag',\n",
       " 'quiet desperation',\n",
       " 'the exception',\n",
       " 'the similarly',\n",
       " 'sequence is',\n",
       " 'inside a',\n",
       " 'that interesting',\n",
       " 'and evil',\n",
       " 'bag ,',\n",
       " 'ho',\n",
       " 'for them',\n",
       " 'film makes',\n",
       " '-LRB- and',\n",
       " \"Jaglom 's\",\n",
       " 'good ideas',\n",
       " 'Intriguing',\n",
       " 'material to',\n",
       " 'blanket',\n",
       " 'serpent',\n",
       " 'but occasionally',\n",
       " 'a worthwhile',\n",
       " 'stories are',\n",
       " 'learn a',\n",
       " 'increase',\n",
       " 'kid-vid',\n",
       " 'schemes ,',\n",
       " 'attached',\n",
       " 'floppy',\n",
       " 'reasonable',\n",
       " 'subgenre',\n",
       " 'for you',\n",
       " 'so similar',\n",
       " 'have made',\n",
       " 'clinic',\n",
       " 'daring and',\n",
       " 'great past',\n",
       " 'maintained',\n",
       " 'than it',\n",
       " 'process ,',\n",
       " 'light and',\n",
       " 'I was',\n",
       " 'gives devastating',\n",
       " 'so I',\n",
       " 'recyclable',\n",
       " 'plants',\n",
       " 'cold ,',\n",
       " 'use',\n",
       " 'and is',\n",
       " 'NOT_seriously',\n",
       " 'trying simply',\n",
       " ', either',\n",
       " 'appeal to',\n",
       " 'light-hearted',\n",
       " 'of lo',\n",
       " 'plays like',\n",
       " 'Scratch',\n",
       " 'hours .',\n",
       " 'months',\n",
       " 'movie equivalent',\n",
       " 'of itself',\n",
       " 'tell a',\n",
       " 'far enough',\n",
       " 'like ,',\n",
       " 'Spring',\n",
       " 'considerably',\n",
       " 'pell-mell',\n",
       " 'truly',\n",
       " 'NOT_emergence',\n",
       " 'weight of',\n",
       " 'crisp and',\n",
       " 'playwriting',\n",
       " 'flavor and',\n",
       " 'co-stars',\n",
       " 'provide an',\n",
       " 'Jackie',\n",
       " 'virtually no',\n",
       " 'woman who',\n",
       " 'dabbles',\n",
       " 'a unique',\n",
       " 'warmed',\n",
       " 'to Williams',\n",
       " 'enjoyably',\n",
       " 'the tortured',\n",
       " 'story in',\n",
       " 'receding',\n",
       " 'heroes of',\n",
       " 'behaving',\n",
       " 'tries and',\n",
       " 'The cast',\n",
       " 'fate',\n",
       " 'their mini',\n",
       " 'the early',\n",
       " 'flaccid',\n",
       " 'NOT_shtick',\n",
       " 'spooky action-packed',\n",
       " 'toward the',\n",
       " 'heat',\n",
       " 'watch for',\n",
       " 'reopens',\n",
       " 'then not',\n",
       " 'suffocate',\n",
       " 'mild',\n",
       " 'disappears',\n",
       " 'Writer',\n",
       " 'small and',\n",
       " 'non-firsthand experience',\n",
       " 'stuff of',\n",
       " 'just ca',\n",
       " 'that film',\n",
       " 'heart-pounding',\n",
       " \"n't as\",\n",
       " 'sequels',\n",
       " \"'s often\",\n",
       " 'an impressive',\n",
       " 'while it',\n",
       " 'storytelling and',\n",
       " 'and enjoy',\n",
       " 'Clements',\n",
       " 'for most',\n",
       " 'plot ;',\n",
       " 'not on',\n",
       " 'corny',\n",
       " 'scintillating',\n",
       " 'hopped-up',\n",
       " 'dominated by',\n",
       " 'repelled by',\n",
       " 'zeitgeist',\n",
       " 'pit',\n",
       " 'looking at',\n",
       " 'has compelling',\n",
       " 'runs 163',\n",
       " 'of view',\n",
       " 'monotone',\n",
       " 'abysmal',\n",
       " \"'re willing\",\n",
       " 'Chris',\n",
       " 'oddest',\n",
       " 'symbolism ,',\n",
       " 'In fact',\n",
       " 'heat of',\n",
       " 'Latin',\n",
       " 'thriller with',\n",
       " 'swings',\n",
       " 'scandals',\n",
       " 'greatly',\n",
       " ', far',\n",
       " 'opts for',\n",
       " 'tendencies',\n",
       " 'mediocre',\n",
       " 'Sterile',\n",
       " 'of mystery',\n",
       " 'trailer-trash',\n",
       " 'Men',\n",
       " 'Martha is',\n",
       " 'suspended',\n",
       " 'us of',\n",
       " 'incorporates',\n",
       " 'inappropriate',\n",
       " 'character to',\n",
       " 'see how',\n",
       " 'Fangoria',\n",
       " 'geriatric Dirty',\n",
       " 'the present',\n",
       " 'budget',\n",
       " 'subject as',\n",
       " 'Tosca',\n",
       " 'tongue-in-cheek weirdness',\n",
       " 'mess that',\n",
       " 'Giles',\n",
       " 'describes',\n",
       " 'A great',\n",
       " 'nudity',\n",
       " 'you go',\n",
       " 'simple premise',\n",
       " 'routine is',\n",
       " 'gets girl',\n",
       " 'really do',\n",
       " 'is almost',\n",
       " 'with dry',\n",
       " 'update',\n",
       " 'Sorority',\n",
       " 'cartoon in',\n",
       " 'feelings',\n",
       " 'the chilly',\n",
       " 'lines ,',\n",
       " 'waydowntown',\n",
       " 'attempt',\n",
       " 'glimpses',\n",
       " 'benefited',\n",
       " 'Philippe',\n",
       " 'usual route',\n",
       " 'bow',\n",
       " 'the Rings',\n",
       " 'permeates',\n",
       " 'simple ,',\n",
       " 'lesson ,',\n",
       " 'MacGraw',\n",
       " 'sputters',\n",
       " 'intimate',\n",
       " 'primal',\n",
       " 'than that',\n",
       " 'Especially',\n",
       " 'lots',\n",
       " 'wazoo',\n",
       " 'aware of',\n",
       " 'or without',\n",
       " 'A hypnotic',\n",
       " 'scenes -RRB-',\n",
       " 'shifted',\n",
       " 'vibrant ,',\n",
       " 'devoid',\n",
       " 'Seldhal',\n",
       " 'avenues',\n",
       " 'it had',\n",
       " 'look behind',\n",
       " 'you appreciate',\n",
       " 'in marriage',\n",
       " 'jolt',\n",
       " 'relying',\n",
       " 'lets things',\n",
       " 'Chill',\n",
       " 'this shocking',\n",
       " 'freak-outs',\n",
       " 'ensure that',\n",
       " 'opera that',\n",
       " 'torture',\n",
       " 'great Saturday',\n",
       " 'heft to',\n",
       " 'are in',\n",
       " 'hoary',\n",
       " 'his next',\n",
       " 'it an',\n",
       " 'Jeopardy',\n",
       " 'sometimes wry',\n",
       " 'tougher',\n",
       " 'yet to',\n",
       " 'in unusual',\n",
       " 'and screenwriters',\n",
       " 'was made',\n",
       " 'Anyone',\n",
       " 'Trials of',\n",
       " 'the-loose',\n",
       " 'showing signs',\n",
       " 'lingering',\n",
       " 'suspected',\n",
       " 'revels',\n",
       " 'an honest',\n",
       " 'owned',\n",
       " 'Beneath',\n",
       " 'safely',\n",
       " 'At times',\n",
       " 'interpretations',\n",
       " 'avoid',\n",
       " 'Ghetto',\n",
       " 'Rye',\n",
       " 'brooding',\n",
       " 'finds its',\n",
       " 'scotches',\n",
       " 'old-fashioned storytelling',\n",
       " \"'s refusal\",\n",
       " 'of Fire',\n",
       " 'fluffy',\n",
       " 'universe',\n",
       " 'Earnest',\n",
       " 'movie could',\n",
       " 'levels',\n",
       " 'Powers in',\n",
       " 'spies',\n",
       " 'cultivated',\n",
       " 'drained',\n",
       " 'reminder that',\n",
       " 'people of',\n",
       " 'black comedy',\n",
       " 'Chilling',\n",
       " 'sexual identity',\n",
       " 'Manas',\n",
       " 'tendentious',\n",
       " 'greatness',\n",
       " 'painfully bad',\n",
       " 'sailor',\n",
       " 'wallowing in',\n",
       " 'Open-ended',\n",
       " 'steaming',\n",
       " 'to witness',\n",
       " 'somebody',\n",
       " 'him .',\n",
       " 'attuned',\n",
       " 'of ridiculousness',\n",
       " 'worn',\n",
       " 'bad as',\n",
       " 'to survive',\n",
       " 'self-destructive man',\n",
       " 'luvvies',\n",
       " 'evocative',\n",
       " '90',\n",
       " 'brash',\n",
       " 'uncovers',\n",
       " 'insulted',\n",
       " ...}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NaiveBayes(vocabulary, tokenisation).get_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    \n",
    "    def __init__(self, vocabulary, tokenisation):\n",
    "        self.dimensions = sorted(list(vocabulary))\n",
    "        self.tokenisation = tokenisation\n",
    "        \n",
    "    \n",
    "    def get_feature_vector(self, review_tokens):\n",
    "        review_tokens = set(review_tokens)\n",
    "        feature_vector = []\n",
    "        for word in self.dimensions:\n",
    "            if word in review_tokens:\n",
    "                feature_vector.append(1)\n",
    "            else:\n",
    "                feature_vector.append(0)\n",
    "        xs = np.array(feature_vector)\n",
    "\n",
    "        # Normalisation\n",
    "        denom = np.linalg.norm(xs)\n",
    "        \n",
    "        if denom == 0:\n",
    "            return xs\n",
    "\n",
    "        return xs / denom\n",
    "    \n",
    "    def split_data(self, indices):\n",
    "        \"\"\"\n",
    "        Given the indices (list of numbers). Split 'data' into negative, neutral and positive sentiments using 'labels'\n",
    "        \"\"\"\n",
    "        subset_data = data[indices]\n",
    "        subset_labels = labels[indices]\n",
    "        \n",
    "        negative_sentiments = np.where(subset_labels == -1)[0]\n",
    "        neutral_sentiments = np.where(subset_labels == 0)[0]\n",
    "        positive_sentiments = np.where(subset_labels == 1)[0]\n",
    "        \n",
    "        return subset_data[negative_sentiments], subset_data[neutral_sentiments], subset_data[positive_sentiments]\n",
    "    \n",
    "    \n",
    "    def get_train_test_data(self, train_index1, train_index2, test_index):\n",
    "        neg_reviews_1, neutral_reviews_1, pos_reviews_1  = self.split_data(train_indices[train_index1])\n",
    "        neg_reviews_2, neutral_reviews_2, pos_reviews_2 = self.split_data(train_indices[train_index2])\n",
    "        negative_reviews, neutral_reviews, positive_reviews = self.split_data(test_indices[test_index])\n",
    "        \n",
    "        train_xs = []\n",
    "        train_ys = []\n",
    "\n",
    "        test_xs = []\n",
    "        test_ys = []\n",
    "        \n",
    "        print(\"Split Data\")\n",
    "\n",
    "        for neg_review in np.concatenate((neg_reviews_1, neg_reviews_2), axis=0):\n",
    "            neg_review_tokens = self.tokenisation(neg_review)\n",
    "            xs = self.get_feature_vector(neg_review_tokens)\n",
    "            train_xs.append(xs)\n",
    "            train_ys.append(-1)  # Label -1 is for negative sentiment\n",
    "            \n",
    "        print(\"Neg train\")\n",
    "\n",
    "        for pos_review in np.concatenate((pos_reviews_1, pos_reviews_2), axis=0):\n",
    "            pos_review_tokens = self.tokenisation(pos_review)\n",
    "            xs = self.get_feature_vector(pos_review_tokens)\n",
    "            train_xs.append(xs)\n",
    "            train_ys.append(1)  # Label 1 for positive sentiment\n",
    "            \n",
    "        print(\"Pos train\")\n",
    "            \n",
    "        for neu_review in np.concatenate((neutral_reviews_1, neutral_reviews_2), axis=0):\n",
    "            neu_review_tokens = self.tokenisation(neu_review)\n",
    "            xs = self.get_feature_vector(neu_review_tokens)\n",
    "            train_xs.append(xs)\n",
    "            train_ys.append(0)  # Label 0 for neutral sentiment\n",
    "            \n",
    "        print(\"Neu train\")\n",
    "\n",
    "        for neg_review in negative_reviews:\n",
    "            neg_review_tokens = self.tokenisation(neg_review)\n",
    "            xs = self.get_feature_vector(neg_review_tokens)\n",
    "            test_xs.append(xs)\n",
    "            test_ys.append(-1)  # Label -1 for negatuve sentiment\n",
    "            \n",
    "        print(\"Neg test\")\n",
    "            \n",
    "        for neu_review in neutral_reviews:\n",
    "            neu_review_tokens = self.tokenisation(neu_review)\n",
    "            xs = self.get_feature_vector(neu_review_tokens)\n",
    "            test_xs.append(xs)\n",
    "            test_ys.append(0)  # Label 0 for neutral sentiment\n",
    "            \n",
    "        print(\"Neu test\")\n",
    "            \n",
    "        for pos_review in positive_reviews:\n",
    "            pos_review_tokens = self.tokenisation(pos_review)\n",
    "            xs = self.get_feature_vector(pos_review_tokens)\n",
    "            test_xs.append(xs)\n",
    "            test_ys.append(1)  # Label 1 for positive sentiment\n",
    "            \n",
    "        print(\"Pos test\")\n",
    "\n",
    "        return np.array(train_xs), np.array(train_ys), np.array(test_xs), np.array(test_ys)\n",
    "    \n",
    "    \n",
    "    def get_statistics(self):\n",
    "        classifier = LinearSVC()\n",
    "        train_xs, train_ys, test_xs, test_ys = self.get_train_test_data(1, 2, 0)\n",
    "        classifier.fit(train_xs, train_ys)\n",
    "        print(\"FITTED\")\n",
    "        accuracy1 = classifier.score(test_xs, test_ys)\n",
    "\n",
    "        classifier = LinearSVC()\n",
    "        train_xs, train_ys, test_xs, test_ys = self.get_train_test_data(0, 2, 1)\n",
    "        classifier.fit(train_xs, train_ys)\n",
    "        accuracy2 = classifier.score(test_xs, test_ys)\n",
    "\n",
    "        classifier = LinearSVC()\n",
    "        train_xs, train_ys, test_xs, test_ys = self.get_train_test_data(0, 1, 2)\n",
    "        classifier.fit(train_xs, train_ys)\n",
    "        accuracy3 = classifier.score(test_xs, test_ys)\n",
    "\n",
    "        return (accuracy1 + accuracy2 + accuracy3) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Data\n",
      "Neg train\n",
      "Pos train\n",
      "Neu train\n",
      "Neg test\n",
      "Neu test\n",
      "Pos test\n",
      "FITTED\n",
      "Split Data\n",
      "Neg train\n",
      "Pos train\n",
      "Neu train\n",
      "Neg test\n",
      "Neu test\n",
      "Pos test\n",
      "Split Data\n",
      "Neg train\n",
      "Pos train\n",
      "Neu train\n",
      "Neg test\n",
      "Neu test\n",
      "Pos test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.92017155006000317"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use same vocabulary as NB above, so no need to recalculate\n",
    "SVM(vocabulary, tokenisation).get_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
