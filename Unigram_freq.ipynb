{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_reviews = [[], [], []]\n",
    "to_search = './Datasets/neg/'\n",
    "for f in os.listdir(to_search):\n",
    "    path = to_search+f\n",
    "    fold = f[:5]\n",
    "    if fold < 'cv233':\n",
    "        fold_index = 0\n",
    "    elif fold < 'cv466':\n",
    "        fold_index = 1\n",
    "    else:\n",
    "        fold_index = 2\n",
    "    with open(path, 'r', encoding='latin-1') as fin:\n",
    "            negative_reviews[fold_index].append(fin.read().strip())\n",
    "            \n",
    "positive_reviews = [[], [], []]\n",
    "to_search = './Datasets/pos/'\n",
    "for f in os.listdir(to_search):\n",
    "    path = to_search+f\n",
    "    fold = f[:5]\n",
    "    if fold < 'cv233':\n",
    "        fold_index = 0\n",
    "    elif fold < 'cv466':\n",
    "        fold_index = 1\n",
    "    else:\n",
    "        fold_index = 2\n",
    "    with open(path, 'r', encoding='latin-1') as fin:\n",
    "            positive_reviews[fold_index].append(fin.read().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The review data already contains tokenised words\n",
    "\"\"\"\n",
    "In NLTK, to use Naive Bayes we supply a list of training data. This is a list of tuples: [(features, label), ...]\n",
    "In this example:\n",
    "Label is a string, denoting the class of the the features\n",
    "\n",
    "Feature is a dictionary of {word: Boolen} saying whether the word is present in this data point. In training examples, this will\n",
    "only contain positive example words, so all boolean will be True.\n",
    "\n",
    "In test example (say if we fix our vector size representing a data point/document) then we would have False for any tokens in \n",
    "vector that is not present in the test data.\n",
    "\n",
    "The NLTK version ignores any words not seen before when calculating probabilities, rather than giving zero probability.\n",
    "It does not do any add-one smoothing.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_not_tag(review):\n",
    "    \"\"\"\n",
    "    Given a tokenised review (string with space after all tokens) we return another string with the NOT_* tag added to \n",
    "    words between negated word and punctuation\n",
    "    \"\"\"\n",
    "    review_ls = review.split()\n",
    "    negation_word = {'not': True, \"isn't\": True, \"doesn't\": True, \"wasn't\":True, \"couldn't\": True, \"wouldn't\": True, \"didn't\": True}\n",
    "    punctuation = {'?': True, '!': True, '.': True, ',': True, ':': True, ';':True}\n",
    "    \n",
    "    convert_word = False\n",
    "    for index in range(len(review_ls)):\n",
    "        word = review_ls[index]\n",
    "        \n",
    "        if word in punctuation:\n",
    "            convert_word = False\n",
    "            continue\n",
    "        \n",
    "        if convert_word:\n",
    "            review_ls[index] = 'NOT_'+word\n",
    "            continue\n",
    "        \n",
    "        if word in negation_word:\n",
    "            convert_word = True\n",
    "            continue\n",
    "            \n",
    "    return ' '.join(review_ls)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 16165 unigrams from 1400 reviews\n",
    "neg_flatlist = [neg_review for fold in negative_reviews for neg_review in fold]\n",
    "pos_flatlist = [pos_review for fold in positive_reviews for pos_review in fold]\n",
    "\n",
    "freq = {}\n",
    "for review in neg_flatlist + pos_flatlist:\n",
    "    \n",
    "    # CHANGED TAG\n",
    "    review = add_not_tag(review)\n",
    "    \n",
    "    for word in review.split():\n",
    "        if word in freq:\n",
    "            freq[word] += 1\n",
    "        else:\n",
    "            freq[word] = 1\n",
    "            \n",
    "sorted_freq = sorted([(count, word) for word, count in freq.items()], reverse=True)\n",
    "vocabulary = set([word for _, word in sorted_freq[:16165]]) # We use set to exploit O(1) lookup time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Implementing custom Naive Bayes. We use log values here instead of exact\n",
    "P(c) = 0.5 since only two classes and equally spread \n",
    "P(d) = We ignore\n",
    "P(f_i|c) = Number of times word f_i occured in a document / total count of words in document. Plus smoothing (1/|V|)\n",
    "\"\"\"\n",
    "\n",
    "def get_freq_test(review):\n",
    "    freq = {v:0 for v in vocabulary}\n",
    "    for word in review.split():\n",
    "        if word in freq:\n",
    "            freq[word] += 1\n",
    "    return freq\n",
    "\n",
    "\n",
    "def get_freq_train(review):\n",
    "    \"\"\"\n",
    "    review: A string containing all the tokens in a training data document. P(f_i|c) from training documents\n",
    "    \"\"\"\n",
    "    # We start with the add-one smoothing\n",
    "    \n",
    "    log_prob_dict = {v:1 for v in vocabulary}\n",
    "    count = 0\n",
    "    for word in review.split():\n",
    "        if word in log_prob_dict:\n",
    "            log_prob_dict[word] += 1\n",
    "            count += 1\n",
    "    \n",
    "    # We divide by the denominator and log the values\n",
    "    for key in log_prob_dict.keys():\n",
    "        # The total words appearing in a document are the ones that are in the vocabulary and count towards the variable 'count'\n",
    "        log_prob_dict[key] = np.log(log_prob_dict[key] / (count + len(vocabulary)))\n",
    "        \n",
    "    return log_prob_dict\n",
    "        \n",
    "\n",
    "def train_and_test(train_index1, train_index2, test_index):\n",
    "    neg_train_ls = []\n",
    "    for neg_review in negative_reviews[train_index1] + negative_reviews[train_index2]:\n",
    "        \n",
    "        # CHANGED TAG\n",
    "        neg_review = add_not_tag(neg_review)\n",
    "        \n",
    "        for neg_word in neg_review.split():\n",
    "            neg_train_ls.append(neg_word)\n",
    "    \n",
    "    neg_train = ' '.join(neg_train_ls)\n",
    "    negative_log_probs = get_freq_train(neg_train)\n",
    "    \n",
    "    pos_train_ls = []\n",
    "    for pos_review in positive_reviews[train_index1] + positive_reviews[train_index2]:\n",
    "        \n",
    "        #CHANGED TAG\n",
    "        pos_review = add_not_tag(pos_review)\n",
    "        \n",
    "        for pos_word in pos_review.split():\n",
    "            pos_train_ls.append(pos_word)\n",
    "    pos_train = ' '.join(pos_train_ls)\n",
    "    positive_log_probs = get_freq_train(pos_train)\n",
    "    \n",
    "#     prior = 0.5  # But since this is same for both we don't actually need to use it\n",
    "    correct = 0\n",
    "    for pos_review in positive_reviews[test_index]:\n",
    "        \n",
    "        # CHANGED TAG\n",
    "        pos_review = add_not_tag(pos_review)\n",
    "        \n",
    "        counts = get_freq_test(pos_review)\n",
    "        neg_sum = 0   # For negative class\n",
    "        pos_sum = 0   # For positive class\n",
    "        for word in counts.keys():\n",
    "            neg_sum += negative_log_probs[word] * counts[word]\n",
    "            pos_sum += positive_log_probs[word] * counts[word]\n",
    "        \n",
    "        if pos_sum > neg_sum:\n",
    "            correct += 1\n",
    "            \n",
    "    for neg_review in negative_reviews[test_index]:\n",
    "        \n",
    "        # CHANGED TAG\n",
    "        neg_review = add_not_tag(neg_review)\n",
    "        \n",
    "        \n",
    "        counts = get_freq_test(neg_review)\n",
    "        neg_sum = 0   # For negative class\n",
    "        pos_sum = 0   # For positive class\n",
    "        for word in counts.keys():\n",
    "            neg_sum += negative_log_probs[word] * counts[word]\n",
    "            pos_sum += positive_log_probs[word] * counts[word]\n",
    "        \n",
    "        if neg_sum > pos_sum:\n",
    "            correct += 1\n",
    "        \n",
    "    return correct / (len(positive_reviews[test_index]) + len(negative_reviews[test_index]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7871104019172689"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans1 = train_and_test(0, 1, 2)\n",
    "ans2 = train_and_test(0, 2, 1)\n",
    "ans3 = train_and_test(1, 2, 0)\n",
    "\n",
    "NB_avg = (ans1 + ans2 + ans3)/3\n",
    "NB_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM\n",
    "\n",
    "We create a feature vector, each dimension is a word from the vocabulary list. The feature vector here contains NOT_ tags too. The values for the vector are the counts of the word occuring in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_vector(dimensions, review):\n",
    "    freq = {}\n",
    "    for word in review.split():\n",
    "        if word in freq:\n",
    "            freq[word] += 1\n",
    "        else:\n",
    "            freq[word] = 1\n",
    "    \n",
    "    feature_vector = []\n",
    "    for word in dimensions:\n",
    "        if word in freq:\n",
    "            feature_vector.append(freq[word])\n",
    "        else:\n",
    "            feature_vector.append(0)\n",
    "    xs = np.array(feature_vector)\n",
    "    \n",
    "    denom = 1\n",
    "#     denom = np.linalg.norm(np.array(list(freq.values())))  # For l2 norm including all the words\n",
    "#     denom = np.linalg.norm(xs)\n",
    "    \n",
    "    return xs / denom\n",
    "\n",
    "\n",
    "def get_data(train_index1, train_index2, test_index):\n",
    "    dimensions = sorted(list(vocabulary))\n",
    "    train_xs = []\n",
    "    train_ys = []\n",
    "    \n",
    "    test_xs = []\n",
    "    test_ys = []\n",
    "    \n",
    "    for neg_review in negative_reviews[train_index1] + negative_reviews[train_index2]:\n",
    "        neg_review = add_not_tag(neg_review) # CHANGED TAG\n",
    "        xs = get_feature_vector(dimensions, neg_review)\n",
    "        train_xs.append(xs)\n",
    "        train_ys.append(-1)  # Label -1 is for negative sentiment\n",
    "        \n",
    "    for pos_review in positive_reviews[train_index1] + positive_reviews[train_index2]:\n",
    "        pos_review = add_not_tag(pos_review)  # CHANGED TAG\n",
    "        xs = get_feature_vector(dimensions, pos_review)\n",
    "        train_xs.append(xs)\n",
    "        train_ys.append(1)  # Label 1 for positive sentiment\n",
    "        \n",
    "    for pos_review in positive_reviews[test_index]:\n",
    "        pos_review = add_not_tag(pos_review)  # CHANGED TAG\n",
    "        xs = get_feature_vector(dimensions, pos_review)\n",
    "        test_xs.append(xs)\n",
    "        test_ys.append(1)  # Label 1 for positive sentiment\n",
    "        \n",
    "    for neg_review in negative_reviews[test_index]:\n",
    "        neg_review = add_not_tag(neg_review)  # CHANGED TAG\n",
    "        xs = get_feature_vector(dimensions, neg_review)\n",
    "        test_xs.append(xs)\n",
    "        test_ys.append(-1)  # Label -1 for positive sentiment\n",
    "        \n",
    "    return train_xs, train_ys, test_xs, test_ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When not normalising vector: 0.70859469571915934\n",
    "\n",
    "When normalising them using account for all words in review, not just words in vocabulary as above we get: 0.69855287773742702\n",
    "\n",
    "When normalising them with just the words in vocabulary: 0.6992651284496777\n",
    "\n",
    "When using l1 norm as above: 0.51500311800740983\n",
    "\n",
    "When dividing each feature vector by the length of the review it came from (including words not in vocabulary): 0.51994301994302006\n",
    "\n",
    "When dividing each feature vector by the length of the review it came from (with only words in vocabulary): Same as l1 norm as equivalent operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When L2 normalising vectors on vocabulary words:\n",
    "(0, 1, 2) = 71.37%\n",
    "(1, 2, 0) = 68.88%\n",
    "(0, 2, 1) = 69.53%\n",
    "Average of above = 69.93%\n",
    "\n",
    "When not normalising vectors:\n",
    "(0, 1, 2) = 65.81%\n",
    "(0, 2, 1) = 70.82%\n",
    "(1, 2, 0) = 68.24%\n",
    "Average of above = 68.29%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68.29"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(65.81 + 70.82 + 68.24) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_train_test():\n",
    "    train_xs, train_ys, test_xs, test_ys = get_data(0, 1, 2)\n",
    "    with open('../../svm_light/train.txt', 'w') as fout:\n",
    "        for vector, label in zip(train_xs, train_ys):\n",
    "            vector_ls = [str(label)]\n",
    "            for index, value in enumerate(vector):\n",
    "                # Model needs feature numbers to start from 1\n",
    "                vector_ls.append(str(index+1)+':'+str(value))\n",
    "            # NEED NEWLINE CHARACTER AT END. PYTHON AUTOMATICALLY CONVERTS THIS TO APPROPRIATE ENDING\n",
    "            line = ' '.join(vector_ls)+'\\n'\n",
    "            fout.write(line)\n",
    "            \n",
    "    with open('../../svm_light/test.txt', 'w') as fout:\n",
    "        for vector, label in zip(test_xs, test_ys):\n",
    "            vector_ls = [str(label)]\n",
    "            for index, value in enumerate(vector):\n",
    "                vector_ls.append(str(index+1)+':'+str(value))\n",
    "            line = ' '.join(vector_ls)+'\\n'\n",
    "            fout.write(line)\n",
    "            \n",
    "output_train_test()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning examples...done\n",
      "Reading examples into memory...100..200..300..400..500..600..700..800..900..OK. (934 examples read)\n",
      "Setting default regularization parameter C=0.0001\n",
      "Optimizing.....................................................................................................................................................................................................................................................................................................................................................................................................done. (390 iterations)\n",
      "Optimization finished (252 misclassified, maxdiff=0.00100).\n",
      "Runtime in cpu-seconds: 10.76\n",
      "Number of SV: 805 (including 761 at upper bound)\n",
      "L1 loss: loss=599.24630\n",
      "Norm of weight vector: |w|=0.16067\n",
      "Norm of longest example vector: |x|=235.63743\n",
      "Estimated VCdim of classifier: VCdim<=1434.10464\n",
      "Computing XiAlpha-estimates...done\n",
      "Runtime for XiAlpha-estimates in cpu-seconds: 0.07\n",
      "XiAlpha-estimate of the error: error<=85.87% (rho=1.00,depth=0)\n",
      "XiAlpha-estimate of the recall: recall=>14.13% (rho=1.00,depth=0)\n",
      "XiAlpha-estimate of the precision: precision=>14.13% (rho=1.00,depth=0)\n",
      "Number of kernel evaluations: 33150\n",
      "Writing model file...done\n",
      "Reading model...OK. (805 support vectors read)\n",
      "Classifying test examples..100..200..300..400..done\n",
      "Runtime (without IO) in cpu-seconds: 0.00\n",
      "Accuracy on test set: 70.17% (327 correct, 139 incorrect, 466 total)\n",
      "Precision/recall on test set: 77.65%/56.65%\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd ../../svm_light/\n",
    "./svm_learn train.txt model.txt\n",
    "./svm_classify test.txt model.txt output.txt\n",
    "rm *.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6992651284496777"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_SVM():\n",
    "    classifier = SVC(kernel='linear')\n",
    "    train_xs, train_ys, test_xs, test_ys = get_data(0, 1, 2)\n",
    "    classifier.fit(train_xs, train_ys)\n",
    "    ans1 = classifier.score(test_xs, test_ys)\n",
    "    \n",
    "    classifier = SVC(kernel='linear')\n",
    "    train_xs, train_ys, test_xs, test_ys = get_data(0, 2, 1)\n",
    "    classifier.fit(train_xs, train_ys)\n",
    "    ans2 = classifier.score(test_xs, test_ys)\n",
    "    \n",
    "    classifier = SVC(kernel='linear')\n",
    "    train_xs, train_ys, test_xs, test_ys = get_data(1, 2, 0)\n",
    "    classifier.fit(train_xs, train_ys)\n",
    "    ans3 = classifier.score(test_xs, test_ys)\n",
    "    \n",
    "    return (ans1 + ans2 + ans3) / 3\n",
    "\n",
    "test_SVM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = preprocessing.normalize(np.array([[1, 2, 3], [4, 5, 6]]))\n",
    "np.sum(temp ** 2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.521080722570108"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_str_to_dict(review):\n",
    "    freq = {}\n",
    "    for word in review.split():\n",
    "        if word in vocabulary:\n",
    "            freq[word] = True\n",
    "        else:\n",
    "            freq[word] = False\n",
    "    return freq\n",
    "\n",
    "\n",
    "def get_data(train_index1, train_index2, test_index):\n",
    "    train_data = []\n",
    "    for neg_fold in negative_reviews[train_index1] + negative_reviews[train_index2]:\n",
    "        for neg_review in neg_fold:\n",
    "            featureset = convert_str_to_dict(neg_review)\n",
    "            train_data.append((featureset, 'negative'))\n",
    "\n",
    "    for pos_fold in positive_reviews[train_index1] + positive_reviews[train_index2]:\n",
    "        for pos_review in pos_fold:\n",
    "            featureset = convert_str_to_dict(pos_review)\n",
    "            train_data.append((featureset, 'positive'))\n",
    "            \n",
    "    test_data = []\n",
    "    for neg_fold in negative_reviews[test_index]:\n",
    "        for neg_review in neg_fold:\n",
    "            featureset = convert_str_to_dict(neg_review)\n",
    "            test_data.append((featureset, 'negative'))\n",
    "\n",
    "    for pos_fold in positive_reviews[test_index]:\n",
    "        for pos_review in pos_fold:\n",
    "            featureset = convert_str_to_dict(pos_review)\n",
    "            test_data.append((featureset, 'positive'))\n",
    "            \n",
    "    return train_data, test_data\n",
    "\n",
    "train_set, test_set = get_data(0, 1, 2)\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
